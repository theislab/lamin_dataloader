{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564dc59-3984-4eb2-a611-bd55d4d0063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys    \n",
    "import yaml\n",
    "from lamin_dataloader.dataset import GeneIdTokenizer\n",
    "from datamodule import MappedCollectionDataModule\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd52272",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fead61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structure:\n",
    "# - data_root\n",
    "#   - gene_token_mapping.pkl\n",
    "#   - h5ads\n",
    "#     - file1.h5ad\n",
    "#     - file2.h5ad\n",
    "\n",
    "data_root = Path('./temp_data')\n",
    "dataset_path = data_root / 'h5ads/'\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "os.makedirs(dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import anndata as ad\n",
    "\n",
    "for filename in [\"4724c395-0c46-46d2-81f7-60fd271fb488.h5ad\", '01209dce-3575-4bed-b1df-129f57fbc031.h5ad']:\n",
    "    bash_command = f\"curl -o {dataset_path}/{filename} 'https://datasets.cellxgene.cziscience.com/{filename}'\"\n",
    "    subprocess.run(bash_command, shell=True)\n",
    "    \n",
    "adata = ad.read_h5ad(data_root / '4724c395-0c46-46d2-81f7-60fd271fb488.h5ad')\n",
    "gene_mapping = adata.var_names.to_series().to_pickle(data_root / 'gene_token_mapping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "056d553b-55a0-4124-9250-e14f990d52d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching cell_type...\n",
      "Caching sex...\n",
      "Dataset 0: 59357 / 59357 tokens\n",
      "Dataset 1: 54765 / 54765 tokens\n",
      "coverage macro: 1.0\n",
      "covarage micro: 1.0\n",
      "Dataset 0: 59357 / 59357 tokens\n",
      "Dataset 1: 54765 / 54765 tokens\n",
      "coverage macro: 1.0\n",
      "covarage micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "gene_mapping_path = data_root / 'gene_token_mapping.pkl'\n",
    "gene_mapping = pd.read_pickle(gene_mapping_path).to_dict()\n",
    "# gene_mapping = {\n",
    "#   '<cls>': 0,\n",
    "#   '<pad>': 1,\n",
    "#   'ENSG00000233576': 2,\n",
    "#   'ENSG00000121410': 3,\n",
    "#   'ENSG00000268895': 4,\n",
    "#   'ENSG00000148584': 5,\n",
    "#   'ENSG00000175899': 6,\n",
    "#   ...\n",
    "# }\n",
    "\n",
    "split = {'train': ['4724c395-0c46-46d2-81f7-60fd271fb488.h5ad', \n",
    "                   '01209dce-3575-4bed-b1df-129f57fbc031.h5ad'\n",
    "                   ],\n",
    "          'val':  ['4724c395-0c46-46d2-81f7-60fd271fb488.h5ad', \n",
    "                   '01209dce-3575-4bed-b1df-129f57fbc031.h5ad'\n",
    "                   ]\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "dataset_args = {\n",
    "  'train':{\n",
    "    'max_tokens': 1000, \n",
    "    }, \n",
    "  'val':{\n",
    "    'max_tokens': 1000, \n",
    "    }\n",
    "  }\n",
    "dataloader_args = {\n",
    "  'train':\n",
    "    {\n",
    "    'shuffle': True,\n",
    "    'num_workers': 1,\n",
    "    'drop_last': True,\n",
    "    'batch_size': 32,\n",
    "    'num_samples': None,\n",
    "    'pin_memory': True,\n",
    "    'filter': {'cell_type': ['neuron', 'ependymal cell'], 'sex': ['male']},\n",
    "    },\n",
    "  'val':\n",
    "    {\n",
    "    'shuffle': True,\n",
    "    'num_workers': 1,\n",
    "    'drop_last': True,\n",
    "    'batch_size': 32,\n",
    "    'num_samples': None,\n",
    "    'pin_memory': True,\n",
    "    },\n",
    "}\n",
    "\n",
    "datamodule_args = {\n",
    "    'dataset_path': dataset_path,\n",
    "    'split': split,\n",
    "    'columns': ['cell_type', 'sex'],\n",
    "    'normalization': 'log1p',\n",
    "    'gene_sampling_strategy': 'top', # 'random' or 'top'\n",
    "    'dataset_kwargs': dataset_args,\n",
    "    'dataloader_kwargs': dataloader_args,\n",
    "    'tokenizer': GeneIdTokenizer(gene_mapping)\n",
    "}\n",
    "\n",
    "datamodule = MappedCollectionDataModule(**datamodule_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71d5c6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train dataloader by 690 batches of size 32 taking 22080 samples from 87226 total samples; num_replicas=1; sum of indices: 1970327325; num_workers=1\n"
     ]
    }
   ],
   "source": [
    "train_loader = datamodule.train_dataloader() \n",
    "for i, batch in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "620cfc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[12598, 30405,  2578,  ...,  5882, 15036, 33474],\n",
       "         [12598, 20065, 30405,  ..., 17867,  1023, 15333],\n",
       "         [12598, 30405,  4399,  ..., 19859, 24154, 19100],\n",
       "         ...,\n",
       "         [12598, 30405,  2578,  ..., 16171,  6910, 28087],\n",
       "         [12598, 30099,  2971,  ..., 44072, 20280, 16712],\n",
       "         [12598, 30099, 21314,  ..., 15407, 41295,  7714]]),\n",
       " 'values': tensor([[7.0800, 5.7236, 5.3132,  ..., 1.7918, 1.7918, 1.7918],\n",
       "         [8.1637, 5.3936, 5.1705,  ..., 1.7918, 1.7918, 1.7918],\n",
       "         [7.0892, 4.7362, 4.6052,  ..., 1.3863, 1.3863, 1.3863],\n",
       "         ...,\n",
       "         [7.0934, 5.8289, 5.4972,  ..., 1.7918, 1.7918, 1.7918],\n",
       "         [6.3986, 4.2195, 4.0775,  ..., 1.0986, 1.0986, 1.0986],\n",
       "         [5.5947, 4.3944, 4.3041,  ..., 0.6931, 0.6931, 0.6931]]),\n",
       " 'dataset_id': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'cell_type': tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]),\n",
       " 'sex': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e360ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train dataloader by 2725 batches of size 32 taking 87200 samples from 87226 total samples; num_replicas=1; sum of indices: 1970327325; num_workers=1\n"
     ]
    }
   ],
   "source": [
    "val_loader = datamodule.val_dataloader() \n",
    "for i, batch in enumerate(val_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4a08e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[22467,  5734, 22646,  ..., 11946, 29187, 52260],\n",
       "         [12598,  8151, 16572,  ...,  8375, 29801, 20108],\n",
       "         [12598,  7353,  5388,  ..., 23629, 23418, 10772],\n",
       "         ...,\n",
       "         [ 8057, 29893, 26825,  ..., 39853, 38195, 59538],\n",
       "         [12598, 30405,  2578,  ...,  2710,  1006, 19626],\n",
       "         [26825, 22646, 29893,  ..., 28781, 53240, 25462]]),\n",
       " 'values': tensor([[3.7612, 3.7377, 3.7136,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [5.1180, 3.8501, 3.8286,  ..., 0.6931, 0.6931, 0.6931],\n",
       "         [4.9127, 3.9120, 3.8918,  ..., 0.6931, 0.6931, 0.6931],\n",
       "         ...,\n",
       "         [4.1744, 4.0254, 3.7612,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [7.2189, 6.3421, 5.7104,  ..., 1.9459, 1.9459, 1.9459],\n",
       "         [3.3673, 3.2189, 3.1355,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " 'dataset_id': tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 1, 1, 1, 1, 1, 0, 1]),\n",
       " 'cell_type': tensor([ 0,  4,  5,  2, 12,  2, 12, 12, 12, 12,  0,  9,  0,  0,  1,  1,  2,  0,\n",
       "          1,  1,  1,  1, 12, 12, 12,  0,  1,  0,  1,  2, 12,  3]),\n",
       " 'sex': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa78371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
